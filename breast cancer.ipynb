{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7857781,"sourceType":"datasetVersion","datasetId":4609005}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# data","metadata":{}},{"cell_type":"code","source":"#Data Preprocessing:\nimport numpy as np\nimport os\nimport cv2\nfrom PIL import Image\n\nimage_directory = \"/kaggle/input/breast-cancer-dataset/Dataset_BUSI_with_GT/\"\n\ndef load_images(image_folder, label_value):\n    images = [img for img in os.listdir(image_directory + image_folder)]\n    for image_name in images:\n        if image_name.split('.')[1] == 'png' and '_mask' not in image_name:\n            image = cv2.imread(image_directory + image_folder + image_name)\n            if image is not None:\n                image = Image.fromarray(image, 'RGB')\n                image = image.resize((SIZE, SIZE))\n                image = np.array(image)\n                dataset.append(image)\n                label.append(label_value)\n\nSIZE = 128\ndataset = []\nlabel = []\n\nload_images('benign/', 0)  # Benign class with label 0\nload_images('malignant/', 1)  # Malignant class with label 1\nload_images('normal/', 2)  # Normal class with label 2\n\n# Convert dataset and label to numpy arrays\ndataset = np.array(dataset)\nlabel = np.array(label)\nprint(\"Dataset shape:\", dataset.shape)\nprint(\"Label shape:\", label.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:50:11.825240Z","iopub.execute_input":"2024-03-16T15:50:11.825941Z","iopub.status.idle":"2024-03-16T15:50:28.652168Z","shell.execute_reply.started":"2024-03-16T15:50:11.825898Z","shell.execute_reply":"2024-03-16T15:50:28.651248Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Dataset shape: (780, 128, 128, 3)\nLabel shape: (780,)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\n# Convert dataset and label to numpy arrays\ndataset = np.array(dataset)\nlabel = np.array(label)\n\nnum_samples, height, width, channels = dataset.shape\nX_flat = dataset.reshape(num_samples, -1)  # Reshape to (samples, height*width*channels)\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_flat, label, test_size=0.10)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10)\nX_train = X_train.reshape(-1, 128, 128, 3)  # Reshape your input data to match the expected input shape\nX_test= X_test.reshape(-1, 128, 128, 3)  # Reshape your input data to match the expected input shape","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:50:45.025797Z","iopub.execute_input":"2024-03-16T15:50:45.026505Z","iopub.status.idle":"2024-03-16T15:50:57.312659Z","shell.execute_reply.started":"2024-03-16T15:50:45.026474Z","shell.execute_reply":"2024-03-16T15:50:57.311669Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-03-16 15:50:46.749824: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-16 15:50:46.749963: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-16 15:50:46.888364: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\n\n# Convert X_train to float32 and reshape it for augmentation\nX_train = X_train.astype('float32')\nX_train = X_train.reshape(-1, 128, 128, 3)\n# Initialize ImageDataGenerators for different classes\n\naugmentation_class0 = ImageDataGenerator(\n    rotation_range=0,\n    width_shift_range=0,\n    height_shift_range=0,\n    horizontal_flip=True,\n    vertical_flip=False\n)\naugmentation_class1 = ImageDataGenerator(\n    rotation_range=5,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.1,\n    shear_range=0.1,\n    horizontal_flip=True,\n    vertical_flip=False\n)\naugmentation_class2 = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    zoom_range=0.2,\n    shear_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=False\n)\n#  y_train contains labels where 0, 1, 2 represent classes 0, 1, 2 respectively\nindices_class0 = np.where(y_train == 0)[0]  # Indices for class 0\nindices_class1 = np.where(y_train == 1)[0]  # Indices for class 1\nindices_class2 = np.where(y_train == 2)[0]  # Indices for class 2\n\nX_class0 = X_train[indices_class0]  # Data corresponding to class 1\nX_class1 = X_train[indices_class1]  # Data corresponding to class 1\nX_class2 = X_train[indices_class2]  # Data corresponding to class 2\n\n# Fit the ImageDataGenerators to respective classes\naugmentation_class0.fit(X_class0)\naugmentation_class1.fit(X_class1)\naugmentation_class2.fit(X_class2)\n\n# Generate augmented images for different classes\naugmented_images_class0 = []\naugmented_images_class1 = []\naugmented_images_class2 = []\nfor x_batch in augmentation_class0.flow(X_class0, batch_size=len(X_class1), shuffle=False):\n    augmented_images_class0.append(x_batch)\n    if len(augmented_images_class0) >= 1.4:\n        break\n        \nfor x_batch in augmentation_class1.flow(X_class1, batch_size=len(X_class1), shuffle=False):\n    augmented_images_class1.append(x_batch)\n    if len(augmented_images_class1) >= 1.5:\n        break\n\nfor x_batch in augmentation_class2.flow(X_class2, batch_size=len(X_class2), shuffle=False):\n    augmented_images_class2.append(x_batch)\n    if len(augmented_images_class2) >=3.0:\n        break\n\n#2.5,3 : best\n# Concatenate augmented data for different classes\nX_augmented_class0 = np.concatenate(augmented_images_class0)\nX_augmented_class1 = np.concatenate(augmented_images_class1)\nX_augmented_class2 = np.concatenate(augmented_images_class2)\n\n# Assuming the labels for augmented data\ny_augmented_class0 = np.full(len(X_augmented_class0), 0)  # Label for class 2\ny_augmented_class1 = np.full(len(X_augmented_class1), 1)  # Label for class 1\ny_augmented_class2 = np.full(len(X_augmented_class2), 2)  # Label for class 2\n\n# Concatenate augmented data and labels with the original data and labels\nX_train_augmented = np.concatenate([X_train,X_augmented_class1, X_augmented_class2])\ny_train_augmented = np.concatenate([y_train, y_augmented_class1, y_augmented_class2])\n\n# Shuffle the augmented dataset\nshuffle_indices = np.random.permutation(len(y_train_augmented))\nX_train = X_train_augmented[shuffle_indices]\ny_train = y_train_augmented[shuffle_indices]\n\n\n# Verify the shape of the augmented dataset\nprint(\"Shape of augmented images:\", X_train.shape)\n# Calculate the number of samples in each class after augmentation\nprint(\"Number of samples in benign :\", len(X_augmented_class0))\nprint(\"Number of samples in malignant after augmentation:\", len(X_augmented_class1))\nprint(\"Number of samples in normal after augmentation:\", len(X_augmented_class2))\n\nfrom sklearn.utils.class_weight import compute_class_weight\n# Compute class weights\nclass_labels = np.unique(y_train)\nclass_weights = compute_class_weight('balanced', classes=class_labels, y=y_train)\nclass_weight = {i: weight for i, weight in enumerate(class_weights)}\n\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:51:16.107493Z","iopub.execute_input":"2024-03-16T15:51:16.108375Z","iopub.status.idle":"2024-03-16T15:51:18.746372Z","shell.execute_reply.started":"2024-03-16T15:51:16.108332Z","shell.execute_reply":"2024-03-16T15:51:18.745476Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Shape of augmented images: (1281, 128, 128, 3)\nNumber of samples in benign : 350\nNumber of samples in malignant after augmentation: 350\nNumber of samples in normal after augmentation: 300\n","output_type":"stream"}]},{"cell_type":"code","source":"\nimport keras\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom keras.utils import to_categorical\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import regularizers\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.metrics import classification_report, accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:51:25.840844Z","iopub.execute_input":"2024-03-16T15:51:25.841698Z","iopub.status.idle":"2024-03-16T15:51:25.855198Z","shell.execute_reply.started":"2024-03-16T15:51:25.841668Z","shell.execute_reply":"2024-03-16T15:51:25.854302Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# efficientnet","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n\nbase_model = EfficientNetB0(weights='imagenet', include_top=False,\n                            input_shape=(128, 128, 3))\n\n# Add custom top layers for your 3-class classification with regularization and dropout\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(3, activation='softmax'))\n\n# Freeze layers from the pre-trained model\nfor layer in base_model.layers[-20:]:  # Unfreeze last 20 layers for fine-tuning\n    layer.trainable = True\n    \n    \n# Compile the model with a lower learning rate and different optimizer\nmodel.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\n# Define the checkpoint path with correct file extension\ncheckpoint_path = '/kaggle/working/best_model_weights.weights.h5'\n\n# Create a ModelCheckpoint callback\ncheckpoint = ModelCheckpoint(checkpoint_path, \n                             monitor='val_accuracy', \n                             verbose=1, \n                             save_best_only=True,\n                             mode='max', \n                             save_weights_only=True)\n\n# Train the model with data augmentation and the modified architecture\nhistory = model.fit(X_train,y_train, class_weight=class_weight, epochs=20, \n                    validation_split=.2, callbacks=[checkpoint], verbose = 1) \n                    \n                    \nmodel.load_weights(checkpoint_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow import keras\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, acc = model.evaluate(X_test, y_test)\nprint(loss)\nprint(acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=model.predict(X_test)\nprint(y_pred)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport numpy as np\n\ny_pred_labels = np.argmax(y_pred, axis=1)\n\n# Generate confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred_labels)\n\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Define class labels\nclasses = ['benign', 'malignant', 'normal']\n\n# Generate confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred_labels)\n\n# Plot confusion matrix\nplt.figure(figsize=(5,5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix')\n\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# InceptionResNetV2","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n\n\nbase_model1 = tf.keras.applications.InceptionResNetV2(\n                include_top=False,\n                weights=\"imagenet\",\n                input_shape=(128, 128, 3)\n            )\n# Add custom top layers for your 3-class classification with regularization and dropout\nmodel1 = Sequential()\nmodel1.add(base_model1)\nmodel1.add(GlobalAveragePooling2D())\nmodel1.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\nmodel1.add(Dropout(0.5))\nmodel1.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\nmodel1.add(Dropout(0.3))\nmodel1.add(Dense(3, activation='softmax'))\n\n# Freeze layers from the pre-trained model\nfor layer in base_model.layers[-20:]:  # Unfreeze last 20 layers for fine-tuning\n    layer.trainable = True\n    \n    \n# Compile the model with a lower learning rate and different optimizer\nmodel1.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\n# Define the checkpoint path with correct file extension\ncheckpoint_path = '/kaggle/working/best_model2_weights.weights.h5'\n# Create a ModelCheckpoint callback\ncheckpoint = ModelCheckpoint(checkpoint_path, \n                             monitor='val_accuracy', \n                             verbose=1, \n                             save_best_only=True,\n                             mode='max', \n                             save_weights_only=True)\n\n# Train the model with data augmentation and the modified architecture\nhistory = model1.fit(X_train,y_train, class_weight=class_weight, epochs=20, \n                    validation_split=.2, callbacks=[checkpoint], verbose = 1) \n                    \n                    \nmodel1.load_weights(checkpoint_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, acc = model1.evaluate(X_test, y_test)\nprint(loss)\nprint(acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred1=model1.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\ny_pred_labels1 = np.argmax(y_pred1, axis=1)\n# Define class labels\nclasses = ['benign', 'malignant', 'normal']\n\n# Generate confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred_labels1)\n\n# Plot confusion matrix\nplt.figure(figsize=(5,5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix')\n\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# resnet","metadata":{}},{"cell_type":"code","source":"\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom keras.layers import Flatten\n# Load ResNet50 as base model\nbase_model12 = ResNet50(weights='imagenet', include_top=False, input_shape=(128,128, 3))\n\n# Freeze the layers of the base model\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Add custom top layers for your 3-class classification with regularization and dropout\nmodel12 = Sequential()\nmodel12.add(base_model12)\nmodel12.add(Flatten())\nmodel12.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\nmodel12.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\nmodel12.add(Dense(3, activation='softmax'))\n\n\n# Compile the model\n#model12.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel12.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nhistory = model12.fit(X_train,y_train, class_weight=class_weight, epochs=20, \n                    validation_split=.2, callbacks=[checkpoint], verbose = 1) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, acc = model12.evaluate(X_test, y_test)\nprint(loss)\nprint(acc)\ny_pred2=model12.predict(X_test)\ny_pred_labels2 = np.argmax(y_pred2, axis=1)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Define class labels\nclasses = ['benign', 'malignant', 'normal']\n\n# Generate confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred_labels2)\n\n# Plot confusion matrix\nplt.figure(figsize=(5,5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# mobilenet","metadata":{}},{"cell_type":"code","source":"\n\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.applications import MobileNet\n\nbase_model3 =MobileNet (weights='imagenet', include_top=False,\n                            input_shape=(128, 128, 3))\n\n# Add custom top layers for your 3-class classification with regularization and dropout\nmodel3 = Sequential()\nmodel3.add(base_model3)\nmodel3.add(GlobalAveragePooling2D())\nmodel3.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\nmodel3.add(Dropout(0.5))\nmodel3.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\nmodel3.add(Dropout(0.3))\nmodel3.add(Dense(3, activation='softmax'))\n\n# Freeze layers from the pre-trained model\nfor layer in base_model3.layers[-20:]:  # Unfreeze last 20 layers for fine-tuning\n    layer.trainable = True\n    \n    \n# Compile the model with a lower learning rate and different optimizer\nmodel3.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\n# Define the checkpoint path with correct file extension\ncheckpoint_path = '/kaggle/working/best_model_weights.weights.h5'\n\n# Create a ModelCheckpoint callback\ncheckpoint = ModelCheckpoint(checkpoint_path, \n                             monitor='val_accuracy', \n                             verbose=1, \n                             save_best_only=True,\n                             mode='max', \n                             save_weights_only=True)\n\n# Train the model with data augmentation and the modified architecture\nhistory = model3.fit(X_train,y_train, class_weight=class_weight, epochs=20, \n                    validation_split=.2, callbacks=[checkpoint], verbose = 1) \n                    \n                    \nmodel3.load_weights(checkpoint_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, acc = model3.evaluate(X_test, y_test)\nprint(loss)\nprint(acc)\n\ny_pred3=model3.predict(X_test)\ny_pred_labels3 = np.argmax(y_pred3, axis=1)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Define class labels\nclasses = ['benign', 'malignant', 'normal']\n\n# Generate confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred_labels3)\n\n# Plot confusion matrix\nplt.figure(figsize=(5,5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# vgg16","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.optimizers import Adam\n\n\n\nbase_model4 =VGG16(weights='imagenet', include_top=False,\n                            input_shape=(128,128, 3))\n\n\n# Freeze the layers of the base model\nfor layer in base_model4.layers:\n    layer.trainable = False\n\n# Add custom top layers for your 3-class classification with regularization and dropout\nmodel4 = Sequential()\nmodel4.add(base_model4)\nmodel4.add(Flatten())\nmodel4.add(Dense(256, activation='relu'))\nmodel4.add(Dense(128, activation='relu'))\nmodel4.add(Dense(3, activation='softmax'))\n\n\n# Compile the model\n#model12.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel4.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nhistory = model4.fit(X_train,y_train, class_weight=class_weight, epochs=20, \n                   validation_split=.2 , verbose = 1) \n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:51:34.726008Z","iopub.execute_input":"2024-03-16T15:51:34.726730Z","iopub.status.idle":"2024-03-16T15:52:08.799631Z","shell.execute_reply.started":"2024-03-16T15:51:34.726699Z","shell.execute_reply":"2024-03-16T15:52:08.798824Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"2024-03-16 15:51:39.667444: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 4.34782, expected 3.51669\n2024-03-16 15:51:39.667505: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 6.71977, expected 5.88864\n2024-03-16 15:51:39.667515: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 6.95696, expected 6.12583\n2024-03-16 15:51:39.667523: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 6.48105, expected 5.64992\n2024-03-16 15:51:39.667531: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 5.32797, expected 4.49684\n2024-03-16 15:51:39.667538: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 5: 5.7497, expected 4.91857\n2024-03-16 15:51:39.667546: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 6.01592, expected 5.18479\n2024-03-16 15:51:39.667554: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 5.52526, expected 4.69413\n2024-03-16 15:51:39.667561: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 4.51707, expected 3.68594\n2024-03-16 15:51:39.667569: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 4.88057, expected 4.04944\n2024-03-16 15:51:39.683331: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,128,128]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-16 15:51:39.683376: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-16 15:51:39.683385: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-16 15:51:39.683393: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-16 15:51:39.683401: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-16 15:51:39.683416: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-03-16 15:51:40.194528: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 4.34782, expected 3.51669\n2024-03-16 15:51:40.194587: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 6.71977, expected 5.88864\n2024-03-16 15:51:40.194597: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 6.95696, expected 6.12583\n2024-03-16 15:51:40.194605: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 6.48105, expected 5.64992\n2024-03-16 15:51:40.194612: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 5.32797, expected 4.49684\n2024-03-16 15:51:40.194620: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 5: 5.7497, expected 4.91857\n2024-03-16 15:51:40.194628: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 6.01592, expected 5.18479\n2024-03-16 15:51:40.194636: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 5.52526, expected 4.69413\n2024-03-16 15:51:40.194643: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 4.51707, expected 3.68594\n2024-03-16 15:51:40.194651: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 4.88057, expected 4.04944\n2024-03-16 15:51:40.209626: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,128,128]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-16 15:51:40.209679: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-16 15:51:40.209688: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-16 15:51:40.209695: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-16 15:51:40.209702: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-16 15:51:40.209717: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3762 - loss: 20.7227","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1710604306.646003     111 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5168 - loss: 11.7011","output_type":"stream"},{"name":"stderr","text":"2024-03-16 15:51:48.678058: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32768: 3.66788, expected 2.82077\n2024-03-16 15:51:48.678112: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32769: 5.27059, expected 4.42348\n2024-03-16 15:51:48.678122: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32770: 5.00058, expected 4.15347\n2024-03-16 15:51:48.678131: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32771: 4.72297, expected 3.87586\n2024-03-16 15:51:48.678139: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32772: 4.5861, expected 3.73899\n2024-03-16 15:51:48.678147: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32773: 4.17555, expected 3.32844\n2024-03-16 15:51:48.678155: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32774: 3.43326, expected 2.58615\n2024-03-16 15:51:48.678164: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32775: 3.61347, expected 2.76636\n2024-03-16 15:51:48.678172: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32776: 2.90622, expected 2.05911\n2024-03-16 15:51:48.678180: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32777: 3.1097, expected 2.26259\n2024-03-16 15:51:48.678196: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[1,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,3,128,128]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-16 15:51:48.678204: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-16 15:51:48.678220: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-16 15:51:48.678228: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-16 15:51:48.678235: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-16 15:51:48.678247: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-03-16 15:51:48.705072: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32768: 3.66788, expected 2.82077\n2024-03-16 15:51:48.705114: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32769: 5.27059, expected 4.42348\n2024-03-16 15:51:48.705132: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32770: 5.00058, expected 4.15347\n2024-03-16 15:51:48.705147: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32771: 4.72297, expected 3.87586\n2024-03-16 15:51:48.705160: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32772: 4.5861, expected 3.73899\n2024-03-16 15:51:48.705174: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32773: 4.17555, expected 3.32844\n2024-03-16 15:51:48.705188: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32774: 3.43326, expected 2.58615\n2024-03-16 15:51:48.705201: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32775: 3.61347, expected 2.76636\n2024-03-16 15:51:48.705222: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32776: 2.90622, expected 2.05911\n2024-03-16 15:51:48.705235: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 32777: 3.1097, expected 2.26259\n2024-03-16 15:51:48.705256: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[1,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,3,128,128]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-16 15:51:48.705267: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-16 15:51:48.705276: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-16 15:51:48.705285: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-16 15:51:48.705295: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-16 15:51:48.705308: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - accuracy: 0.5283 - loss: 11.1485 - val_accuracy: 0.7160 - val_loss: 1.3683\nEpoch 2/20\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8693 - loss: 0.4869 - val_accuracy: 0.7899 - val_loss: 10562.5166\nEpoch 3/20\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9647 - loss: 0.1136 - val_accuracy: 0.8521 - val_loss: 0.5433\nEpoch 4/20\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9863 - loss: 0.0406 - val_accuracy: 0.8444 - val_loss: 2856.2295\nEpoch 5/20\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9962 - loss: 0.0165 - val_accuracy: 0.8444 - val_loss: 0.6654\nEpoch 6/20\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9939 - loss: 0.0474 - val_accuracy: 0.8560 - val_loss: 0.7797\nEpoch 7/20\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9941 - loss: 0.0349 - val_accuracy: 0.8288 - val_loss: 0.8894\nEpoch 8/20\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9866 - loss: 0.0689 - val_accuracy: 0.8366 - val_loss: 0.8269\nEpoch 9/20\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9853 - loss: 0.0880 - val_accuracy: 0.8054 - val_loss: 1.0404\nEpoch 10/20\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9807 - loss: 0.0902 - val_accuracy: 0.8132 - val_loss: 36239.9766\nEpoch 11/20\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9692 - loss: 0.1674 - val_accuracy: 0.7938 - val_loss: 22985.7422\nEpoch 12/20\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9457 - loss: 0.3736 - val_accuracy: 0.8171 - val_loss: 50541.7969\nEpoch 13/20\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9640 - loss: 0.1779 - val_accuracy: 0.8249 - val_loss: 39924.1328\nEpoch 14/20\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9794 - loss: 0.1355 - val_accuracy: 0.8210 - val_loss: 33538.3945\nEpoch 15/20\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9914 - loss: 0.0246 - val_accuracy: 0.8093 - val_loss: 11150.7969\nEpoch 16/20\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9953 - loss: 0.0131 - val_accuracy: 0.8521 - val_loss: 1.1239\nEpoch 17/20\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9915 - loss: 0.0965 - val_accuracy: 0.8482 - val_loss: 1.0036\nEpoch 18/20\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9947 - loss: 0.0234 - val_accuracy: 0.8599 - val_loss: 1.1828\nEpoch 19/20\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9942 - loss: 0.0660 - val_accuracy: 0.8093 - val_loss: 1.7249\nEpoch 20/20\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9869 - loss: 0.0458 - val_accuracy: 0.8210 - val_loss: 57580.4961\n","output_type":"stream"}]},{"cell_type":"code","source":"loss, acc = model4.evaluate(X_test, y_test)\nprint(loss)\nprint(acc)\ny_pred4=model4.predict(X_test)\ny_pred_labels4 = np.argmax(y_pred4, axis=1)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Define class labels\nclasses = ['benign', 'malignant', 'normal']\n\n# Generate confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred_labels4)\n\n# Plot confusion matrix\nplt.figure(figsize=(5,5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:52:13.612429Z","iopub.execute_input":"2024-03-16T15:52:13.612795Z","iopub.status.idle":"2024-03-16T15:52:20.072918Z","shell.execute_reply.started":"2024-03-16T15:52:13.612767Z","shell.execute_reply":"2024-03-16T15:52:20.071984Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 827ms/step - accuracy: 0.8125 - loss: 1.4299","output_type":"stream"},{"name":"stderr","text":"2024-03-16 15:52:14.740074: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 4.35343, expected 3.47357\n2024-03-16 15:52:14.740137: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 5.99384, expected 5.11397\n2024-03-16 15:52:14.740146: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 6.60323, expected 5.72337\n2024-03-16 15:52:14.740154: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 6.4805, expected 5.60063\n2024-03-16 15:52:14.740162: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 5.37986, expected 4.5\n2024-03-16 15:52:14.740170: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 5: 5.45361, expected 4.57374\n2024-03-16 15:52:14.740178: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 4.86515, expected 3.98529\n2024-03-16 15:52:14.740186: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 4.2048, expected 3.32493\n2024-03-16 15:52:14.740199: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 4.39363, expected 3.51376\n2024-03-16 15:52:14.740207: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 4.19159, expected 3.31172\n2024-03-16 15:52:14.746715: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[14,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[14,3,128,128]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-16 15:52:14.746751: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-16 15:52:14.746759: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-16 15:52:14.746766: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-16 15:52:14.746773: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-16 15:52:14.746788: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-03-16 15:52:14.913792: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 4.35343, expected 3.47357\n2024-03-16 15:52:14.913848: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 5.99384, expected 5.11397\n2024-03-16 15:52:14.913857: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 6.60323, expected 5.72337\n2024-03-16 15:52:14.913865: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 6.4805, expected 5.60063\n2024-03-16 15:52:14.913874: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 5.37986, expected 4.5\n2024-03-16 15:52:14.913882: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 5: 5.45361, expected 4.57374\n2024-03-16 15:52:14.913891: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 4.86515, expected 3.98529\n2024-03-16 15:52:14.913899: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 4.2048, expected 3.32493\n2024-03-16 15:52:14.913907: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 4.39363, expected 3.51376\n2024-03-16 15:52:14.913915: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 4.19159, expected 3.31172\n2024-03-16 15:52:14.920973: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[14,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[14,3,128,128]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-16 15:52:14.921004: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-16 15:52:14.921012: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-16 15:52:14.921019: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-16 15:52:14.921026: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-16 15:52:14.921040: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.8101 - loss: 2.5522  \n3.380535125732422\n0.807692289352417\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322ms/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 500x500 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"# deepcnn","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n\ndef DeepCNN(input_shape, num_classes):\n    model = tf.keras.Sequential([\n        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n        MaxPooling2D(pool_size=(2, 2)),\n        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n        MaxPooling2D(pool_size=(2, 2)),\n        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n        Conv2D(256, kernel_size=(3, 3), activation='relu'),\n        MaxPooling2D(pool_size=(2, 2)),\n        Flatten(),\n        Dense(512, activation='relu'),\n        Dense(num_classes, activation='softmax')\n    ])\n    return model\n\n# Define input shape and number of classes\ninput_shape = (128,128,3)  # Example input shape for RGB images\nnum_classes = 3  # Define the number of classes in your dataset\n\n# Create a deep CNN model\nmodel = DeepCNN(input_shape, num_classes)\n\n    \n    \n# Compile the model with a lower learning rate and different optimizer\nmodel.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\n# Define the checkpoint path with correct file extension\ncheckpoint_path = '/kaggle/working/best_model_weights.weights.h5'\n\n# Create a ModelCheckpoint callback\ncheckpoint = ModelCheckpoint(checkpoint_path, \n                             monitor='val_accuracy', \n                             verbose=1, \n                             save_best_only=True,\n                             mode='max', \n                             save_weights_only=True)\n\n# Train the model with data augmentation and the modified architecture\nhistory = model.fit(X_train,y_train, class_weight=class_weight, epochs=20, \n                    validation_split=.2, callbacks=[checkpoint], verbose = 1) \n              \n                    \nmodel.load_weights(checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:52:23.973415Z","iopub.execute_input":"2024-03-16T15:52:23.974044Z","iopub.status.idle":"2024-03-16T15:53:05.997974Z","shell.execute_reply.started":"2024-03-16T15:52:23.974014Z","shell.execute_reply":"2024-03-16T15:53:05.996963Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"2024-03-16 15:52:26.966098: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31758: 7.18885, expected 6.34915\n2024-03-16 15:52:26.966149: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31794: 6.79032, expected 5.95062\n2024-03-16 15:52:26.966159: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31795: 6.91364, expected 6.07395\n2024-03-16 15:52:26.966167: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31796: 7.21123, expected 6.37153\n2024-03-16 15:52:26.966181: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31809: 7.14567, expected 6.30597\n2024-03-16 15:52:26.966189: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31823: 7.30269, expected 6.46299\n2024-03-16 15:52:26.966196: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31824: 7.17199, expected 6.33229\n2024-03-16 15:52:26.966204: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31831: 6.8277, expected 5.98801\n2024-03-16 15:52:26.966212: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31837: 7.37409, expected 6.53439\n2024-03-16 15:52:26.966221: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31920: 7.26745, expected 6.42775\n2024-03-16 15:52:26.973214: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,32,126,126]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,128,128]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-16 15:52:26.973243: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-16 15:52:26.973251: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-16 15:52:26.973258: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-16 15:52:26.973265: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-16 15:52:26.973279: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-03-16 15:52:27.181576: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31758: 7.18885, expected 6.34915\n2024-03-16 15:52:27.181626: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31794: 6.79032, expected 5.95062\n2024-03-16 15:52:27.181635: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31795: 6.91364, expected 6.07395\n2024-03-16 15:52:27.181643: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31796: 7.21123, expected 6.37153\n2024-03-16 15:52:27.181652: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31809: 7.14567, expected 6.30597\n2024-03-16 15:52:27.181660: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31823: 7.30269, expected 6.46299\n2024-03-16 15:52:27.181668: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31824: 7.17199, expected 6.33229\n2024-03-16 15:52:27.181676: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31831: 6.8277, expected 5.98801\n2024-03-16 15:52:27.181683: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31837: 7.37409, expected 6.53439\n2024-03-16 15:52:27.181699: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 31920: 7.26745, expected 6.42775\n2024-03-16 15:52:27.188777: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,32,126,126]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,128,128]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-16 15:52:27.188816: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-16 15:52:27.188824: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-16 15:52:27.188832: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-16 15:52:27.188839: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-16 15:52:27.188856: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.3635 - loss: 148.7950","output_type":"stream"},{"name":"stderr","text":"2024-03-16 15:52:35.955416: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4610: 3.93875, expected 3.42964\n2024-03-16 15:52:35.955535: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 14521: 3.93875, expected 3.42964\n2024-03-16 15:52:35.955552: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 15882: 6.56496, expected 5.80551\n2024-03-16 15:52:35.955560: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 15918: 5.95458, expected 5.19513\n2024-03-16 15:52:35.955568: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 15919: 6.47927, expected 5.71982\n2024-03-16 15:52:35.955576: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 15927: 6.48245, expected 5.723\n2024-03-16 15:52:35.955584: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 15928: 6.2255, expected 5.46605\n2024-03-16 15:52:35.955594: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 15936: 5.89394, expected 5.13449\n2024-03-16 15:52:35.955607: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 15942: 6.58241, expected 5.82296\n2024-03-16 15:52:35.955620: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 15958: 6.55776, expected 5.79831\n2024-03-16 15:52:35.955647: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[1,32,126,126]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,3,128,128]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-16 15:52:35.955667: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-16 15:52:35.955725: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-16 15:52:35.955737: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-16 15:52:35.955747: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-16 15:52:35.955761: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-03-16 15:52:35.982031: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4610: 3.93875, expected 3.42964\n2024-03-16 15:52:35.982120: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 14521: 3.93875, expected 3.42964\n2024-03-16 15:52:35.982135: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 15882: 6.56496, expected 5.80551\n2024-03-16 15:52:35.982145: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 15918: 5.95458, expected 5.19513\n2024-03-16 15:52:35.982173: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 15919: 6.47927, expected 5.71982\n2024-03-16 15:52:35.982185: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 15927: 6.48245, expected 5.723\n2024-03-16 15:52:35.982199: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 15928: 6.2255, expected 5.46605\n2024-03-16 15:52:35.982212: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 15936: 5.89394, expected 5.13449\n2024-03-16 15:52:35.982225: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 15942: 6.58241, expected 5.82296\n2024-03-16 15:52:35.982238: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 15958: 6.55776, expected 5.79831\n2024-03-16 15:52:35.982261: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[1,32,126,126]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,3,128,128]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-16 15:52:35.982277: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-16 15:52:35.982290: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-16 15:52:35.982300: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-16 15:52:35.982312: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-16 15:52:35.982328: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_accuracy improved from -inf to 0.56031, saving model to /kaggle/working/best_model_weights.weights.h5\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 100ms/step - accuracy: 0.3654 - loss: 142.9628 - val_accuracy: 0.5603 - val_loss: 64390.6328\nEpoch 2/20\n\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5668 - loss: 0.9399\nEpoch 2: val_accuracy did not improve from 0.56031\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5650 - loss: 0.9417 - val_accuracy: 0.4825 - val_loss: 75965.9922\nEpoch 3/20\n\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5075 - loss: 0.9715\nEpoch 3: val_accuracy did not improve from 0.56031\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5082 - loss: 0.9722 - val_accuracy: 0.4669 - val_loss: 83231.5703\nEpoch 4/20\n\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5637 - loss: 0.9235\nEpoch 4: val_accuracy did not improve from 0.56031\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5642 - loss: 0.9228 - val_accuracy: 0.4825 - val_loss: 84992.0312\nEpoch 5/20\n\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5887 - loss: 0.8802\nEpoch 5: val_accuracy improved from 0.56031 to 0.56809, saving model to /kaggle/working/best_model_weights.weights.h5\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.5893 - loss: 0.8802 - val_accuracy: 0.5681 - val_loss: 85810.6641\nEpoch 6/20\n\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.7721\nEpoch 6: val_accuracy improved from 0.56809 to 0.58755, saving model to /kaggle/working/best_model_weights.weights.h5\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.6719 - loss: 0.7725 - val_accuracy: 0.5875 - val_loss: 108753.3203\nEpoch 7/20\n\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6862 - loss: 0.6948\nEpoch 7: val_accuracy improved from 0.58755 to 0.60700, saving model to /kaggle/working/best_model_weights.weights.h5\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.6848 - loss: 0.6971 - val_accuracy: 0.6070 - val_loss: 118386.8359\nEpoch 8/20\n\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6991 - loss: 0.7561\nEpoch 8: val_accuracy did not improve from 0.60700\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6979 - loss: 0.7552 - val_accuracy: 0.5992 - val_loss: 155816.1250\nEpoch 9/20\n\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7354 - loss: 0.5596\nEpoch 9: val_accuracy improved from 0.60700 to 0.63813, saving model to /kaggle/working/best_model_weights.weights.h5\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - accuracy: 0.7360 - loss: 0.5599 - val_accuracy: 0.6381 - val_loss: 154199.1562\nEpoch 10/20\n\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8553 - loss: 0.3962\nEpoch 10: val_accuracy improved from 0.63813 to 0.64981, saving model to /kaggle/working/best_model_weights.weights.h5\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.8531 - loss: 0.3979 - val_accuracy: 0.6498 - val_loss: 164759.0156\nEpoch 11/20\n\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8681 - loss: 0.3235\nEpoch 11: val_accuracy improved from 0.64981 to 0.67315, saving model to /kaggle/working/best_model_weights.weights.h5\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.8686 - loss: 0.3234 - val_accuracy: 0.6732 - val_loss: 161444.8281\nEpoch 12/20\n\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8797 - loss: 0.2962\nEpoch 12: val_accuracy did not improve from 0.67315\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8808 - loss: 0.2952 - val_accuracy: 0.6576 - val_loss: 165355.8750\nEpoch 13/20\n\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9406 - loss: 0.1811\nEpoch 13: val_accuracy did not improve from 0.67315\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9402 - loss: 0.1822 - val_accuracy: 0.6537 - val_loss: 162655.3438\nEpoch 14/20\n\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9410 - loss: 0.1929\nEpoch 14: val_accuracy did not improve from 0.67315\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9411 - loss: 0.1926 - val_accuracy: 0.6615 - val_loss: 166562.0156\nEpoch 15/20\n\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9767 - loss: 0.0923\nEpoch 15: val_accuracy improved from 0.67315 to 0.71206, saving model to /kaggle/working/best_model_weights.weights.h5\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.9767 - loss: 0.0930 - val_accuracy: 0.7121 - val_loss: 166950.9219\nEpoch 16/20\n\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9794 - loss: 0.0771\nEpoch 16: val_accuracy did not improve from 0.71206\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9792 - loss: 0.0770 - val_accuracy: 0.6265 - val_loss: 163090.1562\nEpoch 17/20\n\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9882 - loss: 0.0654\nEpoch 17: val_accuracy did not improve from 0.71206\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9882 - loss: 0.0649 - val_accuracy: 0.7043 - val_loss: 169537.1875\nEpoch 18/20\n\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9873 - loss: 0.0625\nEpoch 18: val_accuracy did not improve from 0.71206\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9871 - loss: 0.0629 - val_accuracy: 0.6732 - val_loss: 169541.4062\nEpoch 19/20\n\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9525 - loss: 0.1446\nEpoch 19: val_accuracy did not improve from 0.71206\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9529 - loss: 0.1430 - val_accuracy: 0.6615 - val_loss: 167990.6719\nEpoch 20/20\n\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9747 - loss: 0.0748\nEpoch 20: val_accuracy did not improve from 0.71206\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9742 - loss: 0.0776 - val_accuracy: 0.6342 - val_loss: 178246.0000\n","output_type":"stream"}]},{"cell_type":"code","source":"loss, acc = model.evaluate(X_test, y_test)\nprint(loss)\nprint(acc)\ny_pred15=model.predict(X_test)\ny_pred_labels15 = np.argmax(y_pred15, axis=1)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Define class labels\nclasses = ['benign', 'malignant', 'normal']\n\n# Generate confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred_labels15)\n\n# Plot confusion matrix\nplt.figure(figsize=(5,5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:53:11.495194Z","iopub.execute_input":"2024-03-16T15:53:11.495853Z","iopub.status.idle":"2024-03-16T15:53:14.787464Z","shell.execute_reply.started":"2024-03-16T15:53:11.495822Z","shell.execute_reply":"2024-03-16T15:53:14.786563Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 582ms/step - accuracy: 0.6875 - loss: 2.0698","output_type":"stream"},{"name":"stderr","text":"2024-03-16 15:53:12.245554: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16053: 5.59949, expected 4.92021\n2024-03-16 15:53:12.245614: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16054: 5.29957, expected 4.62029\n2024-03-16 15:53:12.245630: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16062: 5.49836, expected 4.81908\n2024-03-16 15:53:12.245644: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16063: 5.71858, expected 5.03929\n2024-03-16 15:53:12.245656: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16218: 5.67184, expected 4.99255\n2024-03-16 15:53:12.245667: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16309: 5.69257, expected 5.01329\n2024-03-16 15:53:12.245685: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16426: 5.16342, expected 4.48413\n2024-03-16 15:53:12.245695: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16451: 5.41102, expected 4.73174\n2024-03-16 15:53:12.245705: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16452: 4.4603, expected 3.78101\n2024-03-16 15:53:12.245715: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16466: 5.76537, expected 5.08609\n2024-03-16 15:53:12.245737: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[14,32,126,126]{3,2,1,0}, u8[0]{0}) custom-call(f32[14,3,128,128]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-16 15:53:12.245749: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-16 15:53:12.245761: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-16 15:53:12.245772: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-16 15:53:12.245782: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-16 15:53:12.245799: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-03-16 15:53:12.316218: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16053: 5.59949, expected 4.92021\n2024-03-16 15:53:12.316273: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16054: 5.29957, expected 4.62029\n2024-03-16 15:53:12.316288: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16062: 5.49836, expected 4.81908\n2024-03-16 15:53:12.316302: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16063: 5.71858, expected 5.03929\n2024-03-16 15:53:12.316320: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16218: 5.67184, expected 4.99255\n2024-03-16 15:53:12.316333: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16309: 5.69257, expected 5.01329\n2024-03-16 15:53:12.316345: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16426: 5.16342, expected 4.48413\n2024-03-16 15:53:12.316356: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16451: 5.41102, expected 4.73174\n2024-03-16 15:53:12.316368: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16452: 4.4603, expected 3.78101\n2024-03-16 15:53:12.316380: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 16466: 5.76537, expected 5.08609\n2024-03-16 15:53:12.316407: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[14,32,126,126]{3,2,1,0}, u8[0]{0}) custom-call(f32[14,3,128,128]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-16 15:53:12.316422: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-16 15:53:12.316433: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-16 15:53:12.316444: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-16 15:53:12.316456: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-16 15:53:12.316475: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 786ms/step - accuracy: 0.5767 - loss: 108.4026\n214.56146240234375\n0.5128205418586731\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 201ms/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 500x500 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# alexnet","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.models import Model\n\ndef AlexNet(input_shape, num_classes):\n    # Define input layer\n    inputs = Input(shape=input_shape)\n\n    # Convolutional layers\n    x = Conv2D(96, (11, 11), strides=(4, 4), activation='relu', padding='same')(inputs)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n    \n    x = Conv2D(256, (5, 5), activation='relu', padding='same')(x)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n    \n    x = Conv2D(384, (3, 3), activation='relu', padding='same')(x)\n    \n    x = Conv2D(384, (3, 3), activation='relu', padding='same')(x)\n    \n    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n\n    # Flatten and fully connected layers\n    x = Flatten()(x)\n    x = Dense(4096, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    \n    x = Dense(4096, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    \n    outputs = Dense(num_classes, activation='softmax')(x)\n\n    # Create model\n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n\n# Define input shape and number of classes\ninput_shape = (128,128, 3)  # AlexNet takes 227x227 images\nnum_classes = 3  # Define the number of classes in your dataset\n\n# Create AlexNet model\nmodel7 = AlexNet(input_shape, num_classes)\n\n\n    \n    \n# Compile the model with a lower learning rate and different optimizer\nmodel7.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\n# Define the checkpoint path with correct file extension\ncheckpoint_path = '/kaggle/working/best_model_weights.weights.h5'\n\n# Create a ModelCheckpoint callback\ncheckpoint = ModelCheckpoint(checkpoint_path, \n                             monitor='val_accuracy', \n                             verbose=1, \n                             save_best_only=True,\n                             mode='max', \n                             save_weights_only=True)\n\n# Train the model with data augmentation and the modified architecture\nhistory = model7.fit(X_train,y_train, class_weight=class_weight, epochs=20, \n                    validation_split=.2, callbacks=[checkpoint], verbose = 1) \n                    \n                    \nmodel7.load_weights(checkpoint_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, acc = model7.evaluate(X_test, y_test)\nprint(loss)\nprint(acc)\ny_pred7=model7.predict(X_test)\ny_pred_labels7 = np.argmax(y_pred7, axis=1)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Define class labels\nclasses = ['benign', 'malignant', 'normal']\n\n# Generate confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred_labels7)\n\n# Plot confusion matrix\nplt.figure(figsize=(5,5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# vgg19","metadata":{}},{"cell_type":"code","source":"\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n\nfrom tensorflow.keras.optimizers import Adam\n\nfrom tensorflow.keras.applications import VGG19\n\nbase_model41 =VGG19(weights='imagenet', include_top=False,\n                            input_shape=(128,128, 3))\n\n\n# Freeze the layers of the base model\nfor layer in base_model41.layers:\n    layer.trainable = False\n\n# Add custom top layers for your 3-class classification with regularization and dropout\nmodel41 = Sequential()\nmodel41.add(base_model41)\nmodel41.add(Flatten())\nmodel41.add(Dense(256, activation='relu'))\nmodel41.add(Dense(128, activation='relu'))\nmodel41.add(Dense(3, activation='softmax'))\n\n\n# Compile the model\n#model12.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel41.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nhistory = model41.fit(X_train,y_train, class_weight=class_weight, epochs=20, \n                    validation_split=.2, verbose = 1) \n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, acc = model41.evaluate(X_test, y_test)\nprint(loss)\nprint(acc)\ny_pred41=model41.predict(X_test)\ny_pred_labels41 = np.argmax(y_pred41, axis=1)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Define class labels\nclasses = ['benign', 'malignant', 'normal']\n\n# Generate confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred_labels41)\n\n# Plot confusion matrix\nplt.figure(figsize=(5,5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# polynet","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, GlobalAveragePooling2D, Dense\nfrom tensorflow.keras.models import Model\n\ndef ConvUnit(inputs, num_filters, kernel_size=(3, 3), activation='relu', padding='same'):\n    x = Conv2D(num_filters, kernel_size, activation=activation, padding=padding)(inputs)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    return x\n\ndef PolyNet(input_shape, num_classes):\n    inputs = Input(shape=input_shape)\n    \n    # Convolutional units with different kernel sizes\n    conv1 = ConvUnit(inputs, 32, kernel_size=(3, 3))\n    conv2 = ConvUnit(inputs, 32, kernel_size=(5, 5))\n    conv3 = ConvUnit(inputs, 32, kernel_size=(7, 7))\n    \n    # Concatenate feature maps from different convolutional units\n    x = concatenate([conv1, conv2, conv3], axis=-1)\n    \n    # Global Average Pooling\n    x = GlobalAveragePooling2D()(x)\n    \n    # Fully connected layers\n    x = Dense(128, activation='relu')(x)\n    output = Dense(num_classes, activation='softmax')(x)\n    \n    model = Model(inputs=inputs, outputs=output)\n    return model\n\n\n\n# Define input shape and number of classes\ninput_shape = (128,128, 3)  # AlexNet takes 227x227 images\nnum_classes = 3  # Define the number of classes in your dataset\n\n\n\nmodel11= PolyNet(input_shape, num_classes)\n    \n    \n# Compile the model with a lower learning rate and different optimizer\nmodel11.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\n# Define the checkpoint path with correct file extension\ncheckpoint_path = '/kaggle/working/best_model_weights.weights.h5'\n\n# Create a ModelCheckpoint callback\ncheckpoint = ModelCheckpoint(checkpoint_path, \n                             monitor='val_accuracy', \n                             verbose=1, \n                             save_best_only=True,\n                             mode='max', \n                             save_weights_only=True)\n\n# Train the model with data augmentation and the modified architecture\nhistory = model11.fit(X_train,y_train, class_weight=class_weight, epochs=20, \n                    validation_split=.2, callbacks=[checkpoint], verbose = 1) \n                    \n                    \nmodel11.load_weights(checkpoint_path)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, acc = model11.evaluate(X_test, y_test)\nprint(loss)\nprint(acc)\ny_pred22=model11.predict(X_test)\ny_pred_labels22= np.argmax(y_pred22, axis=1)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Define class labels\nclasses = ['benign', 'malignant', 'normal']\n\n# Generate confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred_labels22)\n\n# Plot confusion matrix\nplt.figure(figsize=(5,5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}